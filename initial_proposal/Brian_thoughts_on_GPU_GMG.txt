===== PREAMBLE =====
Below are my thoughts on GPUs and geometric multigrid. Feel free to reword as
necessary.
====================


Scaling geometric multigrid (GMG) algorithms on GPUs is a high priority for
both Castro and Maestro, both of which use BoxLib's Fortran 90-based GMG
solver. The massive parallelism on GPUs amplifies the scalability challenges
which GMG algorithms already face on current multi-core architectures,
particularly with regard to load imbalance at coarse levels of the multigrid
hierarchy. Happily, our integration of the emerging benchmark GMG code HPGMG
[1] as a drop-in replacement solver in the BoxLib framework has provided a
possible solution to this problem. Recently, NVIDIA ported HPGMG to CUDA [2],
exploiting the Unified Memory feature introduced in CUDA 6, which simplifies
data synchronization between host and GPU memory. They pursued a ``hybrid''
CUDA implementation, in which relaxations at coarse levels with small grids
execute on the CPU, while those at the fine levels with large grids execute on
the GPU. They tuned empirically the grid size threshold which decides whether a
relaxation will take place on the host or the GPU, and found that they could
accelerate the GMG code by a factor of 4 over the pure-CPU version of HPGMG.

We will leverage this knowledge to explore similar implementations in BoxLib.
Although BoxLib's GMG solvers are more general-purpose than HPGMG (e.g., they
support mixed boundary conditions, refined meshes, arbitrarily shaped
rectangular grids, cell-centered and nodal meshes, etc.), the heart of NVIDIA's
hybrid approach to GPU acceleration would benefit our in-house solvers as well.

[1] https://hpgmg.org/
[2] https://devblogs.nvidia.com/parallelforall/high-performance-geometric-multi-grid-gpu-acceleration/
